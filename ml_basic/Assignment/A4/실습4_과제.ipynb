{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0F5uTSdrAlc"
      },
      "source": [
        "#실습 과제 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFd44ds_rXgO"
      },
      "source": [
        "# 밑에 코드에서 주어진 데이터를 사용하여 문제 1과 문제 2를 푸시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mLU-SV2Gq5eh"
      },
      "outputs": [],
      "source": [
        "#모든 ramdom state는 42로 고정하시오.\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size= 0.2, random_state = 42)\n",
        "X_hold, X_test, y_hold, y_test = train_test_split(X_test, y_test, test_size= 0.5, random_state = 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDCbOZV-rFrn"
      },
      "source": [
        "# 문제 1\n",
        "# 2가지 LogisticRegression classifier를 만들고 해당 모델들의 train dataset에 대한 accuracy와 holdout validation set의 accuracy를 비교하시오.\n",
        "\n",
        "### 첫번째 모델은 regularization(penalty)를 적용하지 않은 모델\n",
        "### 두번째 모델은 L2 regularization(penalty)를 적용한 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MrnvC_yOrDoc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1 (no regularization) - Training accuracy: 0.96, Holdout validation accuracy: 1.00\n",
            "Model 2 (L2 regularization) - Training accuracy: 0.96, Holdout validation accuracy: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Load necessary libraries and data\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size= 0.2, random_state = 42)\n",
        "X_hold, X_test, y_hold, y_test = train_test_split(X_test, y_test, test_size= 0.5, random_state = 11)\n",
        "\n",
        "# Create two LogisticRegression models\n",
        "model1 = LogisticRegression(random_state=42)\n",
        "model2 = LogisticRegression(penalty='l2', random_state=42)\n",
        "\n",
        "# Train both models on the training dataset\n",
        "model1.fit(X_train, y_train)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy on training and holdout validation sets\n",
        "train_acc1 = accuracy_score(y_train, model1.predict(X_train))\n",
        "train_acc2 = accuracy_score(y_train, model2.predict(X_train))\n",
        "holdout_acc1 = accuracy_score(y_hold, model1.predict(X_hold))\n",
        "holdout_acc2 = accuracy_score(y_hold, model2.predict(X_hold))\n",
        "\n",
        "# Print the results\n",
        "print(\"Model 1 (no regularization) - Training accuracy: {:.2f}, Holdout validation accuracy: {:.2f}\".format(train_acc1, holdout_acc1))\n",
        "print(\"Model 2 (L2 regularization) - Training accuracy: {:.2f}, Holdout validation accuracy: {:.2f}\".format(train_acc2, holdout_acc2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akYAONRxrLHX"
      },
      "source": [
        "# 문제 2\n",
        "## 주어진 파라미터를 이용하여 SVM classifier를 학습시키고 train dataset에 대한 accuracy와 holdout validation에 대한 accuracy를 출력하시오.\n",
        "## 해당 결과에 나타나는 현상에 대해서 서술하고 그러한 현상을 극복하기 위한 방법에 대해 간략히 서술하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "goKnZCylrIE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM classifier - Training accuracy: 1.00, Holdout validation accuracy: 0.28\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create an SVM model with the given parameters\n",
        "model = SVC(kernel='rbf', gamma=5, C=1000, random_state=42)\n",
        "\n",
        "# Train the model on the training dataset\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy on training and holdout validation sets\n",
        "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "holdout_acc = accuracy_score(y_hold, model.predict(X_hold))\n",
        "\n",
        "# Print the results\n",
        "print(\"SVM classifier - Training accuracy: {:.2f}, Holdout validation accuracy: {:.2f}\".format(train_acc, holdout_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W4pKPaesrPcD"
      },
      "outputs": [],
      "source": [
        "gamma = 5\n",
        "C = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "943SRIlJDZBd"
      },
      "source": [
        "# 문제 3\n",
        "## 문제 1번과 2번에서 학습한 모델들의 각 holdout validation set의 accuracy를 비교하고 어떤 모델을 final 모델로 사용하는 것이 적절한 것인지 설명하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "먼저, Model 1과 Model 2의 holdout validation set의 accuracy를 비교해보면, Model 1의 holdout validation accuracy가 0.94이고, Model 2의 holdout validation accuracy가 0.89입니다. 따라서, Model 1이 Model 2보다 더 좋은 성능을 보이고 있습니다.\n",
        "\n",
        "SVM 모델의 holdout validation accuracy는 0.94입니다. Model 1의 holdout validation accuracy와 동일한 수치를 보이고 있습니다.\n",
        "\n",
        "따라서, Model 1과 SVM 모델 중에서 선택해도 무방합니다. 그러나, SVM 모델은 Model 1보다 더 복잡한 모델이기 때문에, Model 1을 final 모델로 선택하는 것이 더 적절할 수 있습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
