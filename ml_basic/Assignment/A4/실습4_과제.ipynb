{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0F5uTSdrAlc"
      },
      "source": [
        "#실습 과제 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFd44ds_rXgO"
      },
      "source": [
        "# 밑에 코드에서 주어진 데이터를 사용하여 문제 1과 문제 2를 푸시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mLU-SV2Gq5eh"
      },
      "outputs": [],
      "source": [
        "#모든 ramdom state는 42로 고정하시오.\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size= 0.2, random_state = 42)\n",
        "X_hold, X_test, y_hold, y_test = train_test_split(X_test, y_test, test_size= 0.5, random_state = 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDCbOZV-rFrn"
      },
      "source": [
        "# 문제 1\n",
        "# 2가지 LogisticRegression classifier를 만들고 해당 모델들의 train dataset에 대한 accuracy와 holdout validation set의 accuracy를 비교하시오.\n",
        "\n",
        "### 첫번째 모델은 regularization(penalty)를 적용하지 않은 모델\n",
        "### 두번째 모델은 L2 regularization(penalty)를 적용한 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MrnvC_yOrDoc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1 (no regularization) - Training accuracy: 0.96, Holdout validation accuracy: 1.00\n",
            "Model 2 (L2 regularization) - Training accuracy: 0.96, Holdout validation accuracy: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리와 데이터를 불러옵니다.\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = load_wine()\n",
        "# 데이터를 train set과 test set으로 나눕니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size= 0.2, random_state = 42)\n",
        "# test set을 다시 holdout validation set과 test set으로 나눕니다.\n",
        "X_hold, X_test, y_hold, y_test = train_test_split(X_test, y_test, test_size= 0.5, random_state = 11)\n",
        "\n",
        "# 두 개의 LogisticRegression 모델을 생성합니다.\n",
        "model1 = LogisticRegression(random_state=42)\n",
        "model2 = LogisticRegression(penalty='l2', random_state=42)\n",
        "\n",
        "# 두 모델을 training dataset으로 학습시킵니다.\n",
        "model1.fit(X_train, y_train)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# training set과 holdout validation set에 대한 정확도를 평가합니다.\n",
        "train_acc1 = accuracy_score(y_train, model1.predict(X_train))\n",
        "train_acc2 = accuracy_score(y_train, model2.predict(X_train))\n",
        "holdout_acc1 = accuracy_score(y_hold, model1.predict(X_hold))\n",
        "holdout_acc2 = accuracy_score(y_hold, model2.predict(X_hold))\n",
        "\n",
        "# 결과를 출력합니다.\n",
        "print(\"Model 1 (no regularization) - Training accuracy: {:.2f}, Holdout validation accuracy: {:.2f}\".format(train_acc1, holdout_acc1))\n",
        "print(\"Model 2 (L2 regularization) - Training accuracy: {:.2f}, Holdout validation accuracy: {:.2f}\".format(train_acc2, holdout_acc2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akYAONRxrLHX"
      },
      "source": [
        "# 문제 2\n",
        "## 주어진 파라미터를 이용하여 SVM classifier를 학습시키고 train dataset에 대한 accuracy와 holdout validation에 대한 accuracy를 출력하시오.\n",
        "## 해당 결과에 나타나는 현상에 대해서 서술하고 그러한 현상을 극복하기 위한 방법에 대해 간략히 서술하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "goKnZCylrIE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM classifier - Training accuracy: 1.00, Holdout validation accuracy: 0.28\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "gamma = 5\n",
        "C = 1000\n",
        "\n",
        "# 주어진 파라미터를 이용하여 SVM 모델을 생성합니다.\n",
        "model = SVC(kernel='rbf', gamma=gamma, C=C, random_state=42)\n",
        "\n",
        "# 학습 데이터셋으로 모델을 학습시킵니다.\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 학습 데이터셋과 holdout validation set에 대한 정확도를 평가합니다.\n",
        "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "holdout_acc = accuracy_score(y_hold, model.predict(X_hold))\n",
        "\n",
        "# 결과를 출력합니다.\n",
        "print(\"SVM classifier - Training accuracy: {:.2f}, Holdout validation accuracy: {:.2f}\".format(train_acc, holdout_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "943SRIlJDZBd"
      },
      "source": [
        "# 문제 3\n",
        "## 문제 1번과 2번에서 학습한 모델들의 각 holdout validation set의 accuracy를 비교하고 어떤 모델을 final 모델로 사용하는 것이 적절한 것인지 설명하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "첫 번째 모델과 두 번째 모델은 모두 훈련 정확도가 0.96이고, 홀드아웃 검증 정확도가 1.00으로 매우 높은 성능을 보이고 있습니다. 이는 모델이 훈련 데이터에 잘 맞춰져 있으며, 검증 데이터에 대해서도 높은 정확도를 보이고 있음을 의미합니다. 그러나 첫 번째 모델은 정규화를 적용하지 않았기 때문에, 새로운 데이터에 대한 일반화 성능이 떨어질 수 있습니다. 반면에 두 번째 모델은 L2 정규화를 적용하여 모델의 복잡도를 제한함으로써 새로운 데이터에 대한 일반화 성능이 더 좋을 것으로 예상됩니다.\n",
        "\n",
        "SVM 분류기의 경우, 훈련 정확도가 1.00으로 매우 높지만, 홀드아웃 검증 정확도가 0.28로 매우 낮습니다. 이는 모델이 훈련 데이터에 과적합되어 있으며, 새로운 데이터에 대한 일반화 성능이 매우 떨어진다는 것을 의미합니다.\n",
        "\n",
        "따라서 세 가지 모델 중에서 final 모델로 선택하는 것이 적절한 것은 두 번째 모델, 즉 L2 정규화를 적용한 모델입니다. 이 모델은 훈련 데이터에 잘 맞춰져 있을 뿐만 아니라, 홀드아웃 검증 데이터에 대해서도 높은 정확도를 보이고 있으며, 정규화를 통해 모델의 복잡도를 제한함으로써 새로운 데이터에 대한 일반화 성능도 좋을 것으로 예상됩니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
