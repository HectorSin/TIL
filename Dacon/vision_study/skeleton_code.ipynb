{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 구성\n",
    "- 본 문제의 목표는 기존의 MNIST와 다르게,\n",
    "- **문자 속에 숨어있는 숫자를 예측**하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    digit letter  0  1  2  3  4  5  6  7  ...  774  775  776  777  778  779  \\\n",
       "id                                        ...                                 \n",
       "1       5      L  1  1  1  4  3  0  0  4  ...    2    1    0    1    2    4   \n",
       "2       0      B  0  4  0  0  4  1  1  1  ...    0    3    0    1    4    1   \n",
       "3       4      L  1  1  2  2  1  1  1  0  ...    3    3    3    0    2    0   \n",
       "4       9      D  1  2  0  2  0  4  0  3  ...    3    3    2    0    1    4   \n",
       "5       6      A  3  0  2  4  0  3  0  4  ...    4    4    3    2    1    3   \n",
       "\n",
       "    780  781  782  783  \n",
       "id                      \n",
       "1     4    4    3    4  \n",
       "2     4    2    1    2  \n",
       "3     3    0    2    2  \n",
       "4     0    0    1    1  \n",
       "5     4    3    1    2  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.set_index('id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 787)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train은 digit, letter, 0~783(pixels)의 총 786개의 column과 2,048개의 instance로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>K</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     letter  0  1  2  3  4  5  6  7  8  ...  774  775  776  777  778  779  \\\n",
       "id                                      ...                                 \n",
       "2049      L  0  4  0  2  4  2  3  1  0  ...    2    0    4    2    2    4   \n",
       "2050      C  4  1  4  0  1  1  0  2  2  ...    0    3    2    4    2    4   \n",
       "2051      S  0  4  0  1  3  2  3  0  2  ...    1    3    2    0    3    2   \n",
       "2052      K  2  1  3  3  3  4  3  0  0  ...    3    0    3    2    4    1   \n",
       "2053      W  1  0  1  1  2  2  1  4  1  ...    4    3    1    4    0    2   \n",
       "\n",
       "      780  781  782  783  \n",
       "id                        \n",
       "2049    3    4    1    4  \n",
       "2050    2    2    1    2  \n",
       "2051    3    0    1    4  \n",
       "2052    0    4    4    4  \n",
       "2053    1    2    3    4  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.set_index('id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 786)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test은 letter, 0~783(pixels)의 총 785개의 column과 2,048개의 instance로 구성\n",
    "- `digit`이 우리가 예측하고자 하는 target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train.query(\"letter == 'A'\")[\n",
    "    [(str(i)) for i in range(784)]\n",
    "].iloc[28].values.reshape(28, 28)\n",
    "plt.imshow(img)\n",
    "plt.title(train.query(\"letter == 'A'\").iloc[28]['digit'], fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        774\n",
       "digit       4\n",
       "letter      A\n",
       "Name: 773, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query(\"letter == 'A'\").iloc[28].iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 이미지는 `A` 문자 속에 `4`가 숨이있다!\n",
    "- 모든 이미지들은 위와 같이 생겼음.\n",
    "- 4를 예측하는 것이 우리의 목표."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN을 사용해보자!\n",
    "- CNN은 영상 처리 기법을 DEEP LEARNING으로 구현한 것(이라고 저는 이해)\n",
    "- 아래 커널을 이미지마다 적용, Convolution 연산(가중합)을 취해 이미지의 특성을 파악하는 것이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x129abe76470>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이런 식으로 특성을 파악하는 것이 목적이다.\n",
    "\n",
    "kernel = np.array(\n",
    "    [\n",
    "        [0, -100, 0],\n",
    "        [0, 255, 0],\n",
    "        [0, -100, 0],\n",
    "    ]\n",
    ")\n",
    "plt.imshow(correlate2d(img, kernel, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 구축\n",
    "\n",
    "- `LightGBM`\n",
    "- `PyTorch - CNN`\n",
    "- `Keras - CNN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자 데이터를 one-hot encoding하고\n",
    "# 이미지 픽셀 데이터를 784개의 위치 feature라고 생각하고 concat\n",
    "X_train = pd.concat(\n",
    "    (pd.get_dummies(train.letter), train[[str(i) for i in range(784)]]), \n",
    "    axis=1)\n",
    "y_train = train['digit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C      D      E      F      G      H      I      J  ...  \\\n",
       "0  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "1  False   True  False  False  False  False  False  False  False  False  ...   \n",
       "2  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "3  False  False  False   True  False  False  False  False  False  False  ...   \n",
       "4   True  False  False  False  False  False  False  False  False  False  ...   \n",
       "\n",
       "   774  775  776  777  778  779  780  781  782  783  \n",
       "0    2    1    0    1    2    4    4    4    3    4  \n",
       "1    0    3    0    1    4    1    4    2    1    2  \n",
       "2    3    3    3    0    2    0    3    0    2    2  \n",
       "3    3    3    2    0    1    4    0    0    1    1  \n",
       "4    4    4    3    2    1    3    4    3    1    2  \n",
       "\n",
       "[5 rows x 810 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       0\n",
       "2       4\n",
       "3       9\n",
       "4       6\n",
       "       ..\n",
       "2043    6\n",
       "2044    1\n",
       "2045    9\n",
       "2046    0\n",
       "2047    5\n",
       "Name: digit, Length: 2048, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set을 8:2로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\신재현\\git\\TIL\\Dacon\\vision_study\\skeleton_code.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/%EC%8B%A0%EC%9E%AC%ED%98%84/git/TIL/Dacon/vision_study/skeleton_code.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/%EC%8B%A0%EC%9E%AC%ED%98%84/git/TIL/Dacon/vision_study/skeleton_code.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lgb \u001b[39m=\u001b[39m LGBMClassifier(device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# GPU를 쓰려면 따로 설치해줘야 함.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/%EC%8B%A0%EC%9E%AC%ED%98%84/git/TIL/Dacon/vision_study/skeleton_code.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# http://www.kwangsiklee.com/2018/05/lightgbm-사용시-gpu-가속하기/\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/%EC%8B%A0%EC%9E%AC%ED%98%84/git/TIL/Dacon/vision_study/skeleton_code.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 위의 링크 참고할 것.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(device='gpu') # GPU를 쓰려면 따로 설치해줘야 함.\n",
    "# http://www.kwangsiklee.com/2018/05/lightgbm-사용시-gpu-가속하기/\n",
    "# 위의 링크 참고할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               device='gpu', importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 적합\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5536585365853659\n"
     ]
    }
   ],
   "source": [
    "# 예측 정확도 출력\n",
    "print((lgb.predict(X_valid) == y_valid.values).sum() / len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터에 대해 예측을 진행\n",
    "X_test = pd.concat(\n",
    "    (pd.get_dummies(test.letter), test[[str(i) for i in range(784)]]), \n",
    "axis=1)\n",
    "\n",
    "# Submission 컬럼에 이를 기록\n",
    "submission.digit = lgb.predict(X_test)\n",
    "\n",
    "# 파일로 저장 후 업로드\n",
    "submission.to_csv('first_submission.csv', index=False) # 57.84313725% 의 결과를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch - CNN\n",
    "- 입력 이미지의 shape을 `(batch_size, n_channels, width, height)`로 넣어줘야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자는 one-hot encoding한 후에 (-1, 1, 26)으로 reshape\n",
    "# pixel값들도 (-1, 1, 784)로 reshape\n",
    "# 그 후 concat하여 (2048, 1, 810)으로 X_train 구축\n",
    "X_train = np.concatenate(\n",
    "    [\n",
    "        pd.get_dummies(train.letter).values.reshape(-1, 1, 26),\n",
    "        (train[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 1, 784)\n",
    "    ], \n",
    "    axis=2\n",
    ")\n",
    "# Label Setting\n",
    "y_train = train['digit'].values\n",
    "\n",
    "# Train-Test를 8:2로 분할\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1638, 1, 810), (410, 1, 810), (1638,), (410,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch.Tensor로 형변환\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_valid = torch.Tensor(X_valid)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_valid = torch.LongTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (\n",
    "    TensorDataset, \n",
    "    DataLoader, \n",
    "    RandomSampler, \n",
    "    SequentialSampler\n",
    ")\n",
    "\n",
    "\n",
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(\n",
    "    X_train[:, :, :26], # Letter\n",
    "    X_train[:, :, 26:].reshape(-1, 1, 28, 28), # Image (28, 28)\n",
    "    y_train # Label\n",
    ")\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(\n",
    "    X_valid[:, :, :26], # Letter\n",
    "    X_valid[:, :, 26:].reshape(-1, 1, 28, 28), # Image (28, 28)\n",
    "    y_valid # Label\n",
    ")\n",
    "validation_sampler = SequentialSampler(\n",
    "    validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Construct\n",
    "\n",
    "class ConvClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Letter를 처리할 1D Conv Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(16, 64, 4, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 5, padding=2), nn.ReLU(),\n",
    "            nn.Conv1d(128, 64, 4, padding=2), nn.ReLU(),\n",
    "            nn.Conv1d(64, 16, 3), nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Image를 처리할 2D Conv Block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 128, 5, padding=2), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 9, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, 9, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, 5, padding=3), nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 위 두 블럭을 지나 concat후 Fully Connected를 지나\n",
    "        # label을 예측\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(22016, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        \n",
    "        # 다중 Label이므로 Cross Entropy Loss를 정의\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x1, x2, label=False):\n",
    "        out = self._inference(x1, x2)\n",
    "        if label is not False:\n",
    "            # label이 입력으로 들어오면 loss도 계산해서 return\n",
    "            loss = self.loss(out, label)\n",
    "            return (out, loss)\n",
    "        # label이 입력되지 않으면 ``self._inference``와 동일.\n",
    "        return out\n",
    "    \n",
    "    def _inference(self, x1, x2):\n",
    "        bsz = x1.size(0)\n",
    "        \n",
    "        x1 = self.conv1(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x1 = x1.view(bsz, -1)\n",
    "        x2 = x2.view(bsz, -1)\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "#         return x\n",
    "        out = F.softmax(self.out(x), dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvClassifier(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(16, 64, kernel_size=(4,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (5): ReLU()\n",
       "    (6): Conv1d(128, 64, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(64, 16, kernel_size=(3,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 512, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(512, 256, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=22016, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 구축\n",
    "model = ConvClassifier()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력이 제대로 들어갈 지 확인\n",
    "x1 = X_train[:32, :, :26].cuda()\n",
    "x2 = X_train[:32, :, 26:].reshape(-1, 1, 28, 28).cuda()\n",
    "\n",
    "model(x1, x2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = Adam(\n",
    "    model.parameters(),\n",
    "    lr=2e-5, # 학습률\n",
    "    eps=1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    ")\n",
    "\n",
    "# 에폭수\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/150] Avg Training Loss: 1.54 Valid Acc: 0.69\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "history = defaultdict(list)\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        x1, x2, label = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(x1, x2, label)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[1]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "        history['train_loss'].append(loss.item())\n",
    "        \n",
    "        # 정확도 계산\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label = label.to('cpu').numpy()\n",
    "        tmp_train_accuracy = flat_accuracy(logits, label)\n",
    "        history['train_acc'].append(tmp_train_accuracy)\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        x1, x2, label = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(x1, x2, label)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "        history['eval_loss'].append(outputs[1].item())\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label = label.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label)\n",
    "        history['eval_acc'].append(tmp_eval_accuracy)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    s = f'\\r[Epoch {epoch_i+1}/{epochs}]'\n",
    "    s += f' Avg Training Loss: {avg_train_loss:.2f}'\n",
    "    s += \" Valid Acc: {0:.2f}\".format(eval_accuracy/nb_eval_steps)\n",
    "    print(s, end='')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 parameter를 저장\n",
    "torch.save(model.state_dict(), 'convclf200803.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvClassifier(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(16, 64, kernel_size=(4,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (5): ReLU()\n",
       "    (6): Conv1d(128, 64, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(64, 16, kernel_size=(3,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 512, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(512, 256, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=22016, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 로드하여 test를 진행할 것임\n",
    "model = ConvClassifier()\n",
    "model.load_state_dict(torch.load('convclf200803.pt'))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test셋 전처리\n",
    "X_test = np.concatenate(\n",
    "    [\n",
    "        pd.get_dummies(test.letter).values.reshape(-1, 1, 26),\n",
    "        (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 1, 784)\n",
    "    ], \n",
    "    axis=2\n",
    ")\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "x1 = X_test[:, :, :26].cuda()\n",
    "x2 = X_test[:, :, 26:].reshape(-1, 1, 28, 28).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "test_data = TensorDataset(x1, x2)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 예측 실시\n",
    "y_pred = []\n",
    "for batch in test_dataloader:\n",
    "    input1, input2 = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input1, input2)\n",
    "    y_pred.append(torch.argmax(outputs, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.digit = torch.cat(y_pred).detach().cpu().numpy()\n",
    "\n",
    "submission.to_csv('second_submission.csv', index=False) # 0.6960784314%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras - CNN\n",
    "- 입력 이미지의 shape을 `(batch_size, width, height, n_channels)`로 넣어줘야 함.\n",
    "- Keras 모델과 Torch 모델을 한 노트북에서 돌릴 경우, GPU할당 문제로 오류가 뜸.\n",
    "- 아래 코드를 다른 노트북에 옮겨서 새롭게 라이브러리, 데이터를 호출 후 진행 바람."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout, MaxPool2D,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add\n",
    ")\n",
    "\n",
    "# LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# How to check if Keras is using GPU?\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (train[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(train['digit'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아마 성능 향상의 가장 큰 요인, 데이터 증강\n",
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 325,578\n",
      "Trainable params: 325,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECREASE LEARNING RATE EACH EPOCH\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN: Epochs=45, Train accuracy=0.78355, Validation accuracy=0.78049\n"
     ]
    }
   ],
   "source": [
    "epochs = 45\n",
    "# Train-Test를 9:1로 분리\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(\n",
    "    X_train, y_train, test_size = 0.1)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(X_train2, y_train2, batch_size=32),\n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=X_train2.shape[0]//32,\n",
    "    validation_data=(X_val2, y_val2), \n",
    "    callbacks=[annealer], \n",
    "    verbose=0\n",
    ")\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['acc']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_acc']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter 및 모델 구조 저장\n",
    "model.save_weights(f'params.h5')\n",
    "    \n",
    "model_json = model.to_json()\n",
    "with open(f\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 진행\n",
    "X_test = (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 28, 28, 1)\n",
    "results = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.digit = results\n",
    "submission.to_csv('1234.csv', index=False) # 0.795575446%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결론\n",
    "- 여러 아이디어가 있었으나, 일단 딥러닝은 깊게 쌓고 많이 돌려봐야 과적합인지 과소적합인지가 나오는 듯.\n",
    "- 많이 쌓고 연산 돌려봅시다.\n",
    "- 구조에 대한 이해도가 필요할 듯\n",
    "- 의외로 LeakyReLU냐 그냥 ReLU냐에 따른 성능 차이도 존재\n",
    "- skip-connection 등 여러 개념을 적용하며 성능을 높여보자!\n",
    "- letter의 정보를 적극적으로 활용할 방안이 있을까?\n",
    "- 어지간하면 keras쓰자. torch로 짜기엔 너무 할게 많...\n",
    "- 그리고 성능도 keras가 우리같은 입문자에겐 더 좋다. 이미 성능이 좋기로 알려진 초기화 기법들, 과적합 방지 기술들이 잘 구현되어 있다!!\n",
    "- Learning Rate 조절도 신경써서 해보자!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
